##Define a Convolutional Neural Network
#MLP1
for a in range(30, 301, 30):
    class MLP(nn.Module):                    #继承nn.module

        def __init__(self):
            super(MLP, self).__init__()      #继承的作用
            self.layer1 = nn.Linear(784,a) #hidden layer-300
            self.relu = nn.ReLU()
            self.layer2 = nn.Linear(a,10)  #ouput layer-10

        def forward(self,x):             #网络传播的结构
            x = x.reshape(-1, 28*28)
            x = self.layer1(x)
            x = self.relu(x)
            y = self.layer2(x)
            return y

    mlp = MLP() #类的实例化
    
    
   ##Define a Loss function and optimizer
loss_func = nn.CrossEntropyLoss()
#optimizer = torch.optim.Adam(mlp.parameters(), lr=learning_rate)

# criterion = nn.CrossEntropyLoss()  #交叉熵损失
optimizer = torch.optim.SGD(mlp.parameters(), lr=0.001, momentum=0.9)


##Train the network
for epoch in range(num_epochs):  # loop over the dataset multiple times
    for i, (images, labels) in enumerate(train_loader): ## get the inputs; data is a list of [inputs, labels]
        optimizer.zero_grad()    # zero the parameter gradients 清零梯度
        # forward + backward + optimize
        outputs = mlp(images)
        loss = loss_func(outputs, labels)
        loss.backward()                                #反向求梯度
        optimizer.step()
        
#         # print statistics
#         if (i+1) % 100 == 0: # print every 100 mini-batches
#             print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))
        

        running_loss += loss.item()
        if i % 2000 == 1999:    
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
            running_loss = 0.0

print('Finished Training')


#Test the network on the test data
#display an image from the test set to look
dataiter = iter(test_loader)
images, labels = next(dataiter)

# print images
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))


#The outputs are energies for the 10 classes. 
#The higher the energy for a class, the more the network thinks that the image is of the particular class. 
#So, let’s get the index of the highest energy:
#测试模型
#mlp.eval()      #测试模式，关闭正则化
correct = 0
total = 0
for images, labels in test_loader:
    outputs = mlp(images)
    _, predicted = torch.max(outputs, 1)   #返回值和索引
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

print('测试准确率: {:.4f}'.format(100.0*correct/total))


#Let us look at how the network performs on the whole dataset.
correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        # calculate outputs by running images through the network
        outputs = mlp(images)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')

# what are the classes that performed well, and the classes that did not perform well:
# prepare to count predictions for each class
correct_pred = {classname: 0 for classname in classes}
total_pred = {classname: 0 for classname in classes}

# again no gradients needed
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        outputs = mlp(images)
        _, predictions = torch.max(outputs, 1)
        # collect the correct predictions for each class
        for label, prediction in zip(labels, predictions):
            if label == prediction:
                correct_pred[classes[label]] += 1
            total_pred[classes[label]] += 1


# print accuracy for each class
for classname, correct_count in correct_pred.items():
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')

#Use PyTorch Profiler to characterize 
#execution time and memory consumption
from torch.profiler import profile, record_function, ProfilerActivity
#Using profiler to analyze memory consumption

with profile(activities=[ProfilerActivity.CPU],
        profile_memory=True, record_shapes=True) as prof:
    mlp(images)
    
#print(prof.key_averages().table(sort_by="self_cpu_memory_usage", row_limit=10))
print(prof.key_averages().table(sort_by="cpu_time_total", row_limit=10))