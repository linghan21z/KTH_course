{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2685b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load training and test datasets using torchvision\n",
    "## define a CNN\n",
    "## loss func\n",
    "## train\n",
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a30677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "#设置一些超参\n",
    "num_epochs = 1        #训练的周期\n",
    "batch_size = 4      #批训练的数量\n",
    "learning_rate = 0.001 #学习率（0.1,0.01,0.001）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9351d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TORCH_HOME']='F:\\jupyter_notebook_file\\Mnist'\n",
    "#导入训练数据\n",
    "train_dataset = datasets.MNIST(root='F:/jupyter_notebook_file/Mnist/',                #数据集保存路径\n",
    "                               train=True,                      #是否作为训练集\n",
    "                               transform=transforms.ToTensor(), #数据如何处理, 可以自己自定义\n",
    "                               download=True)                  #路径下没有的话, 可以下载           \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, #分批\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)          #随机分批\n",
    "#导入测试数据\n",
    "test_dataset = datasets.MNIST(root='F:/jupyter_notebook_file/Mnist/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True,)   \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "classes = ('0','1', '2', '3', '4',\n",
    "           '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d76df14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     0     9     5    \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed7080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define LeNet-5 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfa7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  #subsampling\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # Note that the images were centered in a 28x28 image. \n",
    "        # The standard LeNet-5 assumes the image size 32x32\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "LeNet5 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec0c09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bdadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  #交叉熵损失\n",
    "optimizer = optim.SGD(LeNet5.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51430f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7208aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 1.6575\n",
      "Epoch [1/1], Loss: 0.2985\n",
      "Epoch [1/1], Loss: 0.0678\n",
      "Epoch [1/1], Loss: 0.5066\n",
      "Epoch [1/1], Loss: 0.0054\n",
      "Epoch [1/1], Loss: 0.0630\n",
      "Epoch [1/1], Loss: 0.0250\n",
      "Epoch [1/1], Loss: 0.0357\n",
      "Epoch [1/1], Loss: 0.0200\n",
      "Epoch [1/1], Loss: 0.7020\n",
      "Epoch [1/1], Loss: 0.0248\n",
      "Epoch [1/1], Loss: 0.0045\n",
      "Epoch [1/1], Loss: 0.0108\n",
      "Epoch [1/1], Loss: 0.0783\n",
      "Epoch [1/1], Loss: 0.0022\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    # running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the images; data is a list of [images, labels]\n",
    "        images, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = LeNet5(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if (i+1) % 1000 == 0: # print every 100 mini-batches\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "        \n",
    "\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    \n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "212c2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quickly save our trained model\n",
    "PATH = './LeNet5_net.pth'\n",
    "torch.save(LeNet5.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9b8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "783437d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  7     2     1     0    \n"
     ]
    }
   ],
   "source": [
    "#display an image from the test set to look\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "627df288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load back in our saved model, wasn’t necessary here\n",
    "LeNet5 = Net()\n",
    "LeNet5.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93dd4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = LeNet5(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ed7a502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  7     2     1     0    \n"
     ]
    }
   ],
   "source": [
    "#The outputs are energies for the 10 classes. \n",
    "#The higher the energy for a class, the more the network thinks that the image is of the particular class. \n",
    "#So, let’s get the index of the highest energy:\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dd33730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "#Let us look at how the network performs on the whole dataset.\n",
    "#model.eval()  #测试模式，关闭正则化\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = LeNet5(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a196db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 99.3 %\n",
      "Accuracy for class: 1     is 97.2 %\n",
      "Accuracy for class: 2     is 98.6 %\n",
      "Accuracy for class: 3     is 95.0 %\n",
      "Accuracy for class: 4     is 99.2 %\n",
      "Accuracy for class: 5     is 97.8 %\n",
      "Accuracy for class: 6     is 97.4 %\n",
      "Accuracy for class: 7     is 93.7 %\n",
      "Accuracy for class: 8     is 96.9 %\n",
      "Accuracy for class: 9     is 93.5 %\n"
     ]
    }
   ],
   "source": [
    "# what are the classes that performed well, and the classes that did not perform well:\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = LeNet5(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc1853b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        23.51%       1.314ms       100.00%       5.588ms       5.588ms             1  \n",
      "                     aten::conv2d         0.72%      40.000us        53.76%       3.004ms       1.502ms             2  \n",
      "                aten::convolution         2.81%     157.000us        53.04%       2.964ms       1.482ms             2  \n",
      "               aten::_convolution         1.25%      70.000us        50.23%       2.807ms       1.403ms             2  \n",
      "         aten::mkldnn_convolution        47.35%       2.646ms        48.98%       2.737ms       1.369ms             2  \n",
      "                     aten::linear         0.59%      33.000us         9.41%     526.000us     175.333us             3  \n",
      "                 aten::max_pool2d         0.50%      28.000us         8.07%     451.000us     225.500us             2  \n",
      "    aten::max_pool2d_with_indices         7.57%     423.000us         7.57%     423.000us     211.500us             2  \n",
      "                      aten::addmm         5.37%     300.000us         6.76%     378.000us     126.000us             3  \n",
      "                       aten::relu         1.81%     101.000us         4.42%     247.000us      61.750us             4  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.588ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use PyTorch Profiler to characterize \n",
    "#execution time and memory consumption\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "#Using profiler to analyze execution time\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        LeNet5(images)\n",
    "        \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48890815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                     aten::conv2d         1.93%      22.000us        36.05%     411.000us     411.000us             1                               [[4, 1, 28, 28], [6, 1, 5, 5], [6], [], [], [], []]  \n",
      "                aten::convolution         2.98%      34.000us        34.12%     389.000us     389.000us             1                       [[4, 1, 28, 28], [6, 1, 5, 5], [6], [], [], [], [], [], []]  \n",
      "               aten::_convolution         1.58%      18.000us        31.14%     355.000us     355.000us             1       [[4, 1, 28, 28], [6, 1, 5, 5], [6], [], [], [], [], [], [], [], [], [], []]  \n",
      "         aten::mkldnn_convolution        28.16%     321.000us        29.56%     337.000us     337.000us             1                               [[4, 1, 28, 28], [6, 1, 5, 5], [6], [], [], [], []]  \n",
      "                     aten::conv2d         0.44%       5.000us        20.61%     235.000us     235.000us             1                             [[4, 6, 12, 12], [16, 6, 5, 5], [16], [], [], [], []]  \n",
      "                aten::convolution         1.84%      21.000us        20.18%     230.000us     230.000us             1                     [[4, 6, 12, 12], [16, 6, 5, 5], [16], [], [], [], [], [], []]  \n",
      "               aten::_convolution         0.88%      10.000us        18.33%     209.000us     209.000us             1     [[4, 6, 12, 12], [16, 6, 5, 5], [16], [], [], [], [], [], [], [], [], [], []]  \n",
      "         aten::mkldnn_convolution        16.75%     191.000us        17.46%     199.000us     199.000us             1                             [[4, 6, 12, 12], [16, 6, 5, 5], [16], [], [], [], []]  \n",
      "                     aten::linear         1.05%      12.000us         9.39%     107.000us     107.000us             1                                                     [[4, 256], [120, 256], [120]]  \n",
      "                 aten::max_pool2d         0.70%       8.000us         8.07%      92.000us      92.000us             1                                              [[4, 6, 24, 24], [], [], [], [], []]  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 1.140ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e32325bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        37.14%     781.000us       100.00%       2.103ms       2.103ms           0 b    -199.03 Kb             1  \n",
      "                     aten::conv2d         0.86%      18.000us        37.28%     784.000us     392.000us      70.00 Kb           0 b             2  \n",
      "                aten::convolution         3.52%      74.000us        36.42%     766.000us     383.000us      70.00 Kb           0 b             2  \n",
      "               aten::_convolution         1.57%      33.000us        32.91%     692.000us     346.000us      70.00 Kb           0 b             2  \n",
      "         aten::mkldnn_convolution        29.48%     620.000us        31.34%     659.000us     329.500us      70.00 Kb           0 b             2  \n",
      "                     aten::linear         0.86%      18.000us        12.46%     262.000us      87.333us       3.34 Kb           0 b             3  \n",
      "                      aten::addmm         7.09%     149.000us         9.03%     190.000us      63.333us       3.34 Kb       3.34 Kb             3  \n",
      "                 aten::max_pool2d         0.57%      12.000us         6.23%     131.000us      65.500us      52.50 Kb           0 b             2  \n",
      "                       aten::relu         2.28%      48.000us         5.66%     119.000us      29.750us      73.19 Kb           0 b             4  \n",
      "    aten::max_pool2d_with_indices         5.66%     119.000us         5.66%     119.000us      59.500us      52.50 Kb      52.50 Kb             2  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.103ms\n",
      "\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        37.14%     781.000us       100.00%       2.103ms       2.103ms           0 b    -199.03 Kb             1  \n",
      "                     aten::conv2d         0.86%      18.000us        37.28%     784.000us     392.000us      70.00 Kb           0 b             2  \n",
      "                aten::convolution         3.52%      74.000us        36.42%     766.000us     383.000us      70.00 Kb           0 b             2  \n",
      "               aten::_convolution         1.57%      33.000us        32.91%     692.000us     346.000us      70.00 Kb           0 b             2  \n",
      "         aten::mkldnn_convolution        29.48%     620.000us        31.34%     659.000us     329.500us      70.00 Kb           0 b             2  \n",
      "                     aten::linear         0.86%      18.000us        12.46%     262.000us      87.333us       3.34 Kb           0 b             3  \n",
      "                      aten::addmm         7.09%     149.000us         9.03%     190.000us      63.333us       3.34 Kb       3.34 Kb             3  \n",
      "                 aten::max_pool2d         0.57%      12.000us         6.23%     131.000us      65.500us      52.50 Kb           0 b             2  \n",
      "                       aten::relu         2.28%      48.000us         5.66%     119.000us      29.750us      73.19 Kb           0 b             4  \n",
      "    aten::max_pool2d_with_indices         5.66%     119.000us         5.66%     119.000us      59.500us      52.50 Kb      52.50 Kb             2  \n",
      "                  aten::clamp_min         3.38%      71.000us         3.38%      71.000us      17.750us      73.19 Kb      73.19 Kb             4  \n",
      "                          aten::t         1.57%      33.000us         2.57%      54.000us      18.000us           0 b           0 b             3  \n",
      "                    aten::flatten         0.33%       7.000us         1.24%      26.000us      26.000us           0 b           0 b             1  \n",
      "                      aten::copy_         1.24%      26.000us         1.24%      26.000us       8.667us           0 b           0 b             3  \n",
      "                      aten::empty         1.05%      22.000us         1.05%      22.000us       5.500us      70.00 Kb      70.00 Kb             4  \n",
      "                  aten::transpose         0.67%      14.000us         1.00%      21.000us       7.000us           0 b           0 b             3  \n",
      "                       aten::view         0.90%      19.000us         0.90%      19.000us      19.000us           0 b           0 b             1  \n",
      "                     aten::expand         0.52%      11.000us         0.67%      14.000us       4.667us           0 b           0 b             3  \n",
      "                aten::as_strided_         0.62%      13.000us         0.62%      13.000us       6.500us           0 b           0 b             2  \n",
      "                 aten::as_strided         0.48%      10.000us         0.48%      10.000us       1.667us           0 b           0 b             6  \n",
      "                    aten::resize_         0.19%       4.000us         0.19%       4.000us       2.000us           0 b           0 b             2  \n",
      "               aten::resolve_conj         0.05%       1.000us         0.05%       1.000us       0.167us           0 b           0 b             6  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.103ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using profiler to analyze memory consumption\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU],\n",
    "        profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        LeNet5(images)\n",
    "    \n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c09d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
